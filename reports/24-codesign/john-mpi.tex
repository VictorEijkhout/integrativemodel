   \item \textbf{Improved performance and performance modeling from explicit specification of communication.}   While there is no doubt that the programming model based on sequential languages and communications via MPI libraries has had significant successes, it is clearly not a desirable end goal for parallel programming.   
   
   One significant shortcoming of MPI is the library-based approach, in which the compiler has no knowledge of the communication semantics, and therefore no ability to optimize data motion around MPI calls.  The \ac{IMP} programming model makes the semantics of communication visible, so that the compiler can import dependency information into its intermediate representation and use this in its optimization algorithms.   As an example, a library-based message-passing implementation cannot "know" that the presence of an MPI\_Send() call implies a potentially long-latency operation, and that it may be desirable to begin to move the "source" data to the "destination" as soon as it becomes available, rather than waiting until the library call requires that the data be moved.   Of course it is possible for a programmer to obtain much of this effect by adding non-blocking MPI\_iSend() calls throughout the code as the data to be sent becomes ready, but this is an ugly and error-prone approach to optimization that is much better left to automated analysis.
   
   MPI also remains a labor-intensive approach (it has been called the "moral equivalent of assembly language programming") and creates an unacceptably high barrier to entry for many scientists who could benefit from high-end computing, but who do not have the resources to port and/or maintain MPI codes.  
   
   Semantically, MPI forces the user to craft a data decomposition and work parallelization strategy based on the physical layout of the target system, rather than based on any "natural" data decomposition and work parallelization inherent in the problem under study.  CHARM++ attempts to deal with this problem using an over-decomposition and dynamic load balancing.  While this can be effective, it is perhaps too high an abstraction, and removes the ability of the user to understand and/or control the mapping of communication to the underlying hardware.  
   
