% -*- latex -*-
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%
%%%% This text file is part of the theory writeup on the
%%%% Integrative Model for Parallelism,
%%%% copyright Victor Eijkhout (eijkhout@tacc.utexas.edu) 2014-6
%%%%
%%%% model.tex : include file for IMP-11
%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
In this report we describe the \acf{IMP}. This model purports
to be a better solution to parallel programming in HPC
than currently existing models.

IMP promises the following:
\begin{itemize}
\item Ease of programming: an IMP program is essentially sequential,
  with the user specifying algorithm steps in high level terms
  operating on distributed objects.
\item Mode-independent parallel programming: the same program runs
  with MPI on distributed memory, task models on shared memory,
  or hybrid combinations of these.
\item Asynchronous execution: despite the sequential user language,
  IMP generates a realization of the code in terms of asynchronously
  executing tasks, only governed by their dependencies.
\item Latency-tolerance: the IMP system can analyze codes
  to realize overlap of communication and computation,
  or even do a `communication avoiding' analysis.
\end{itemize}

In the remainder of this introduction we motivate some of the
choices made in the Integrative Model,
while in later sections we discuss the basic concepts
and some practical results.

\subsection{Motivation from programmability}

We argue that many parallel programming systems are too general,
and closely inspired by the target hardware.
For instance message passing
is made necessary by the presence of distributed memory,
while \ac{DAG} models require shared memory and
are naturally attractive in threaded environments.
Both these models have practical disadvantages:
the whole program behaviour is a non-trivial
combination of the behaviours of the strands of execution
that the user codes. Larus and Sutter phrase it as follows~\cite{Sutter_2005}:
\begin{quotation}
    [H]umans are quickly overwhelmed by concurrency and find it much more
    difficult to reason about concurrent than sequential code. Even
    careful people miss possible interleavings among even simple
    collections of partially ordered operations.
\end{quotation}

On the other hand, on a conceptual level, a parallel program
can be fairly simple. For instance, a matrix-vector or
matrix-matrix multiplication is conceptually a single,
even data parallel, operation. All the intricacies of programming
the data distributions needed for a scalable execution of
such operations are really implementation details, and ought not to
concern the user.

The conceptual attraction of such an
approach is eloquently formulated in~\cite{Nikhil93anoverview}:
\begin{quotation}
  [A]n HPF program may be understood (and debugged) using sequential
  semantics, a deterministic world that we are comfortable with. Once
  again, as in traditional programming, the programmer works with a
  single address space, treating an array as a single, monolithic
  object, regardless of how it may be distributed across the memories
  of a parallel machine. The programmer does specify data
  distributions, but these are at a very high level and only have the
  status of hints to the compiler, which is responsible for the actual
  data distribution[.]
\end{quotation}

Thus we argue for a programming model that is on an essentially higher
level than the execution model. The programming model should be more
than syntactic sugar around the execution primitives: it should be
expressed on a level closer to application terms.

\subsection{Realization}

Of course, designing a system with sequential semantics is not easy.
The above mentioned HPF was a notable failure~\cite{Kennedy:riseandfall}
for a variety of reasons, and several other proposed languages
do not seem to scale well to irregular codes on clusters
without further provisions.

\ac{IMP} successfully realizes this goal, based on the following idea.
\begin{itemize}
\item IMP uses dataflow as an Intermediate Representation. Dataflow 
  can serve as an expression of algorithms that enables a wide range
  of parallelism modes; however, instead of programming the dataflow
  formulation explicitly the IMP system derives it from the programmed
  description.
\item Data in the IMP system is organized by distributions. However,
  our notion of distribution more generally than generally used. In
  particular distribution can be dynamically generated by the
  system. We will argue later that this enables the essential
  theoretical innovation behind IMP.
\item In common with several programming systems based on task
  \acp{DAG}, we use an approach where program steps are separately
  declared, analyzed, and executed. This is also known as
  `inspector-executor', and it used in the sparse components of
  libraries such as PETSc and Trilinos.
\end{itemize}
We will motivate the IMP concepts in section~\ref{imp11example} with a
sketch of a formalization. The realization of this in software is
described in section~\ref{sec:realization}.
